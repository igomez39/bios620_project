---
title: "Project I, BIOTAT 620W2022"
author: "Team Hot Pot; Xueting Tao, Isabel Gomez"
date: "2/14/2022"
output: pdf_document
---


# Title:  Give a title of project I. 
# Author:  Xueting Tao, Isabel Gomez

# Abstract:  Write a high-level summary of project I.  

# Introduction: 



# Data Description: 


# Data Preprocessing: 

* Since we all from the first year master student, thus we would like to define Monday to Thursday as school day and Friday to Sunday as non-school day.



#Federated Learning: 



```{r, echo=FALSE,error=FALSE,message=FALSE}

rm(list=ls(all=TRUE))  #same to clear all in stata
cat("\014")

library(xlsx)
library(dplyr)
library(lubridate)
library(stringr)
library(stringi)
library(kableExtra)
#Read in data seperately:
data_D1=read.xlsx("data/hotpot_screen_data.xlsx",sheetName ="isgomez")
data_D2=read.xlsx("data/hotpot_screen_data.xlsx",sheetName ="xuetao")

#Transfer the time into minutes:
data_D1=data_D1 %>%
  mutate(Pickup.1st.minute=(hour(Pickup.1st)*60+minute(Pickup.1st))) %>%
  mutate(pre_Tot.Scr.Time=lag(Tot.Scr.Time),
         pre_Tot.Soc.Time=lag(Tot.Soc.Time),
         X1=pre_Tot.Scr.Time,
         Schoolday=ifelse(Day %in% c("Mo","Tu","We","Th"),1,0),
         X2=Pickups,
         X1Y=X1*Pickup.1st.minute,
         X2Y=X2*Pickup.1st.minute,
         X1square=X1^2,
         X2square=X2^2,
         X1X2=X1*X2)
data_D2=data_D2 %>%
  mutate(Pickup.1st.minute=(hour(Pickup.1st)*60+minute(Pickup.1st))) %>%
  mutate(pre_Tot.Scr.Time=lag(Tot.Scr.Time),
         pre_Tot.Soc.Time=lag(Tot.Soc.Time),
         X1=pre_Tot.Scr.Time,
         Schoolday=ifelse(Day %in% c("Mo","Tu","We","Th"),1,0),
         X2=Pickups,
         X1Y=X1*Pickup.1st.minute,
         X2Y=X2*Pickup.1st.minute,
         X1square=X1^2,
         X2square=X2^2,
         X1X2=X1*X2)
data_D1=data_D1[complete.cases(data_D1),]
data_D2=data_D2[complete.cases(data_D2),]

```

Let D1 denote the data from team member 1 (Isabel) and D2 denote the data from the team member 2(Xueting). Let Y denote the time of first pick-up the following day and X denote the total screen time for the previous day. Following is the formula we used for the linear regression:

Overall Model:

$Y_i=\beta_0+\beta_1*X_{i1}+\epsilon_i$

where :

* $Y_i$ refers to First Pickup time.  
 
* $X_{i1}$ refers to Total Screen time in the previous day


From the principle of Simple linear regression, we could get following formula for the regression coefficients:

* $\hat{\beta_1}=\frac{SSXY(D1\cup D2)}{SSX(D1 \cup D2)}$ 

* $\hat{\beta_0}=\overline{Y}(D1 \cup D2)-\hat{\beta_1}*\overline{X}(D1 \cup D2)$ 

Overall SSXY and SSX could be obtained by the following way:

* $SSXY(D1 \cup D2)=(n_1+n_2)*\left \{ \overline{XY}(D1 \cup D2)-\overline{X}(D1 \cup D2)*\overline{Y}(D1 \cup D2) \right \}$ 

* $SSX(D1 \cup D2)= (n_1+n_2)*\left \{ \overline{X^2}(D1 \cup D2)-{\overline{X}}^2(D1 \cup D2)\right \}$ 

* $\overline{XY}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{XY}(D1)+\frac{n_2}{n_1+n_2}*\overline{XY}(D2)$ 

* $\overline{X}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{X}(D1)+\frac{n_2}{n_1+n_2}*\overline{X}(D2)$ 

* $\overline{Y}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{Y}(D1)+\frac{n_2}{n_1+n_2}*\overline{Y}(D2)$ 

* $\overline{X^2}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{X^2}(D1)+\frac{n_2}{n_1+n_2}*\overline{X^2}(D2)$ 

Also, we learned that the Standard Diviation for $\beta_1$ is defined as the following:

* $SD(\hat{\beta_1})=\sqrt{\hat{Var(\hat{\beta_1})}}=\sqrt{\frac{MSE(D1 \cup D2)}{SSX(D1 \cup D2)}}$ 

* $SD(\hat{\beta_0})=\sqrt{\hat{Var(\hat{\beta_0})}}=\sqrt{MSE*(\frac{1}{n}+\frac{\overline{X}^2(D1 \cup D2)}{SSX(D1 \cup D2)}})$ 

$MSE(D1 \cup D2)$ could be obtained by the following formula: 

* $MSE(D1 \cup D2)=\frac{SSE(D1)+SSE(D2)}{n_1+n_2-2}$ 

* $SSE=\sum_{i=1}^{n}(Y_i-\hat{Y_i})^2$ 

To test Whether the slope ($\beta_1$) is significant from 0, we use the following t-test:

* $\frac{\hat{\beta_1}-\beta_1}{\sqrt{\frac{MSE(D1 \cup D2)}{SSX(D1 \cup D2)}}}\sim t_{n_1+n_2-2}$ 

where $\beta_1=0$


Following is the result utiliziing the method above:

```{r, echo=FALSE,error=FALSE,message=FALSE}


n1=nrow(data_D1)
n2=nrow(data_D2)
#Indivdual mean
XY_D1_bar=mean(data_D1$X1Y,na.rm = T)
XY_D2_bar=mean(data_D2$X1Y,na.rm = T)
X_D1_bar=mean(data_D1$pre_Tot.Scr.Time,na.rm = T)
X_D2_bar=mean(data_D2$pre_Tot.Scr.Time,na.rm = T)
Y_D1_bar=mean(data_D1$Pickup.1st.minute,na.rm = T)
Y_D2_bar=mean(data_D2$Pickup.1st.minute,na.rm = T)
Xsquare_D1_bar=mean(data_D1$X1square,na.rm = T)
Xsquare_D2_bar=mean(data_D2$X1square,na.rm = T)
#Overall mean:
XY_D1D2_bar=n1/(n1+n2)*XY_D1_bar+n2/(n1+n2)*XY_D2_bar
Y_D1D2_bar=n1/(n1+n2)*Y_D1_bar+n2/(n1+n2)*Y_D2_bar
X_D1D2_bar=n1/(n1+n2)*X_D1_bar+n2/(n1+n2)*X_D2_bar
Xsquare_D1D2_bar=n1/(n1+n2)*Xsquare_D1_bar+n2/(n1+n2)*Xsquare_D2_bar
#SSX and SSXY:
SSXY_D1D2=(n1+n2)*(XY_D1D2_bar-X_D1D2_bar*Y_D1D2_bar)
SSX_D1D2=(n1+n2)*(Xsquare_D1D2_bar-(X_D1D2_bar)^2)
beta1_hat=SSXY_D1D2/SSX_D1D2
beta0_hat=Y_D1D2_bar-beta1_hat*X_D1D2_bar
#Pass the estimates back to the individual dataset to get the SSE:
data_D1=data_D1 %>%
  mutate(Yhat=beta0_hat+beta1_hat*pre_Tot.Scr.Time) %>%
  mutate(Ydiff_square=(Yhat-Pickup.1st.minute)^2)
data_D2=data_D2 %>%
  mutate(Yhat=beta0_hat+beta1_hat*pre_Tot.Scr.Time) %>%
  mutate(Ydiff_square=(Yhat-Pickup.1st.minute)^2)

#Calculated SSE seperately
SSE_D1=sum(data_D1$Ydiff_square,na.rm = T)
SSE_D2=sum(data_D2$Ydiff_square,na.rm = T)

#Calculate MSE:
MSE=(SSE_D1+SSE_D2)/(n1+n2-2)

#Calculate SE(beta1_hat):
SD_beta1_hat=sqrt(MSE/SSX_D1D2)
SD_beta0_hat=sqrt(MSE*(1/(n1+n2)+(X_D1D2_bar)^2/SSX_D1D2))

#T score and p value
beta1_tscore=beta1_hat/SD_beta1_hat
beta1_p=2*pt(beta1_tscore, n1+n2-2, lower.tail = FALSE)

beta0_tscore=beta0_hat/SD_beta0_hat
beta0_p=2*pt(beta0_tscore, n1+n2-2, lower.tail = FALSE)

#95% CI
beta1_ul=format(beta1_hat+beta1_tscore*SD_beta1_hat,digits=2)
beta1_ll=format(beta1_hat-beta1_tscore*SD_beta1_hat,digits=2)

beta0_ul=format(beta1_hat+beta0_tscore*SD_beta0_hat,digits=2)
beta0_ll=format(beta1_hat-beta0_tscore*SD_beta0_hat,digits=2)

#Output result in a table:
betalist=format(round(c(beta0_hat,beta1_hat),4))
sdlist=format(round(c(SD_beta0_hat,SD_beta1_hat),4))
tscorelist=format(round(c(beta0_tscore,beta1_tscore),4))
pvaluelist=format(round(c(beta0_p,beta1_p),3))

pvaluelist=str_replace_all(pvaluelist,"0.000","<0.001")

cilist=c(paste0(beta0_ll,",",beta0_ul),paste0(beta1_ll,",",beta1_ul))

#federal learning output table
fed_output=cbind(betalist,sdlist,tscorelist,cilist,pvaluelist)

rname=c("Intercept","Total Screen Time")
cname=c("Coefficient","SD","T-score","95%CI","P-value")
colnames(fed_output)=cname
row.names(fed_output)=rname

kable(fed_output,booktabs = T)

```

From the result above, we found that the estimated $\hat{\beta_1}$ is `r beta1_hat`, with SD=`r SD_beta1_hat`. The calculated P value is `r beta1_p` which is more than 0.05, which is non-significant. 
This results shows that there might be positive relationship between the first pick-up and the total screen time in the previous day but the relationship is not significant.

# Meta Learning: 


Overall Model:

$Y_i=\beta_0+\beta_1*X_{i1}+\beta_2*X_{i2+}\epsilon_i$

where :

* $Y_i$ refers to First Pickup time. 
* $X_{i1}$ refers to Total Screen time in the previous day 
* $X_{i2}$ refers to the Social Sreen time

From the principle of Simple linear regression, we could get following formula for the regression coefficients:

* $\hat{\beta }=(X^TX)^{-1}X^TY$ 

If we define $X_{n*3}=\begin{bmatrix} 1 & X_1^T & X_2^T \end{bmatrix}$ , $Y_{n*1}=\begin{bmatrix} Y_1 & ... & Y_n \end{bmatrix}^T$ where $X_1$, $X_2$ are row vector.

Thus, We have 

$X^TX=\begin{bmatrix}1\\ X_1\\ X_2\end{bmatrix}_{3*n}\begin{bmatrix} 1 & X_1^T & X_2^T \end{bmatrix}_{n*3}=\begin{bmatrix}n & \sum_{i=1}^{n}X_{i1} & \sum_{i=1}^{n}X_{i2} \\ \sum_{i=1}^{n}X_{i1} & \sum_{i=1}^{n}X_{i1}^2 & \sum_{i=1}^{n}X_{i1}X_{i2} \\ \sum_{i=1}^{n}X_{i2} & \sum_{i=1}^{n}X_{i1}X_{i2} & \sum_{i=1}^{n}X_{i2}^2 \end{bmatrix}$

$X^TY=\begin{bmatrix}1\\ X_1\\ X_2\end{bmatrix}_{3*n}\begin{bmatrix} Y_1 & ... & Y_n \end{bmatrix}^T_{n*1}=\begin{bmatrix} \sum_{i=1}^{n}Y_i\\ \sum_{i=1}^{n}Y_iX_{i1} \\ \sum_{i=1}^{n}Y_iX_{i2} \end{bmatrix}$

In summary:

$\hat{\beta }=\begin{bmatrix}1 & \overline{X_{1}} & \overline{X_{2}} \\ \overline{X_{1}} & \overline{X_{1}^2} & \overline{X_{1}X_{2}} \\ \overline{X_{2}} & \overline{X_{1}X_{2}} & \overline{X_{2}^2} \end{bmatrix}^{-1}\begin{bmatrix} \overline{Y}\\ \overline{YX_{1}} \\ \overline{YX_{2}}\end{bmatrix}$

Where, from Federal learning, we have :

* $\overline{YX_1}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{YX_1}(D1)+\frac{n_2}{n_1+n_2}*\overline{YX_1}(D2)$  

* $\overline{YX_2}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{YX_2}(D1)+\frac{n_2}{n_1+n_2}*\overline{YX_2}(D2)$ 

* $\overline{X_1}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{X_1}(D1)+\frac{n_2}{n_1+n_2}*\overline{X_1}(D2)$ 

* $\overline{X_2}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{X_2}(D1)+\frac{n_2}{n_1+n_2}*\overline{X_2}(D2)$ 

* $\overline{Y}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{Y}(D1)+\frac{n_2}{n_1+n_2}*\overline{Y}(D2)$ 

* $\overline{X_1^2}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{X_1^2}(D1)+\frac{n_2}{n_1+n_2}*\overline{X_1^2}(D2)$ 

* $\overline{X_2^2}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{X_2^2}(D1)+\frac{n_2}{n_1+n_2}*\overline{X_2^2}(D2)$ 

* $\overline{X_1X_2}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{X_1X_2}(D1)+\frac{n_2}{n_1+n_2}*\overline{X_1X_2}(D2)$ 


For the Variance of $\hat{\beta}$, we have the variance-covariance matrix defined as the following:

* $\hat{Var(\hat{\beta})}=\hat{\sigma^2}(X^TX)^{-1}=MSE*(X^TX)^{-1}$ 


Where

* $MSE(D1 \cup D2)=\frac{SSE(D1)+SSE(D2)}{n_1+n_2-3}$ 

* $SSE=\sum_{i=1}^{n}(Y_i-\hat{Y_i})^2$ 


To test Whether the coefficient ($\beta_1$ or $\beta_2$) is significant from 0, we use the following t-test: 

* $\frac{\hat{\beta_i}-\beta_i}{\sqrt{\hat{Var(\hat{\beta_i})}}}\sim t_{n_1+n_2-3}$ 

where $\beta_i=0$


Following is the R code implement the formula above:

```{r, echo=FALSE,error=FALSE,message=FALSE}


n1=nrow(data_D1)
n2=nrow(data_D2)
#Indivdual mean
X1Y_D1_bar=mean(data_D1$X1Y,na.rm = T)
X1Y_D2_bar=mean(data_D2$X1Y,na.rm = T)
X2Y_D1_bar=mean(data_D1$X2Y,na.rm = T)
X2Y_D2_bar=mean(data_D2$X2Y,na.rm = T)
X1_D1_bar=mean(data_D1$X1,na.rm = T)
X1_D2_bar=mean(data_D2$X1,na.rm = T)
X2_D1_bar=mean(data_D1$X2,na.rm = T)
X2_D2_bar=mean(data_D2$X2,na.rm = T)
Y_D1_bar=mean(data_D1$Pickup.1st.minute,na.rm = T)
Y_D2_bar=mean(data_D2$Pickup.1st.minute,na.rm = T)
X1square_D1_bar=mean(data_D1$X1square,na.rm = T)
X1square_D2_bar=mean(data_D2$X1square,na.rm = T)
X2square_D1_bar=mean(data_D1$X2square,na.rm = T)
X2square_D2_bar=mean(data_D2$X2square,na.rm = T)
X1X2_D1_bar=mean(data_D1$X1X2,na.rm = T)
X1X2_D2_bar=mean(data_D2$X1X2,na.rm = T)
#Overall mean:
X1Y_D1D2_bar=n1/(n1+n2)*X1Y_D1_bar+n2/(n1+n2)*X1Y_D2_bar
X2Y_D1D2_bar=n1/(n1+n2)*X2Y_D1_bar+n2/(n1+n2)*X2Y_D2_bar
Y_D1D2_bar=n1/(n1+n2)*Y_D1_bar+n2/(n1+n2)*Y_D2_bar
X1_D1D2_bar=n1/(n1+n2)*X1_D1_bar+n2/(n1+n2)*X1_D2_bar
X2_D1D2_bar=n1/(n1+n2)*X2_D1_bar+n2/(n1+n2)*X2_D2_bar
X1square_D1D2_bar=n1/(n1+n2)*X1square_D1_bar+n2/(n1+n2)*X1square_D2_bar
X2square_D1D2_bar=n1/(n1+n2)*X2square_D1_bar+n2/(n1+n2)*X2square_D2_bar
X1X2_D1D2_bar=n1/(n1+n2)*X1X2_D1_bar+n2/(n1+n2)*X1X2_D2_bar

#Matrix and beta hat
XTX_matrix=rbind(c(1,X1_D1D2_bar,X2_D1D2_bar),
                 c(X1_D1D2_bar,X1square_D1D2_bar,X1X2_D1D2_bar),
                 c(X2_D1D2_bar,X1X2_D1D2_bar,X2square_D1D2_bar))
XTX_matrix=as.matrix(XTX_matrix)
XTX_matrix_inverse=solve(XTX_matrix)
XTY_matrix=as.matrix(c(Y_D1D2_bar,X1Y_D1D2_bar,X2Y_D1D2_bar))

beta_hat=XTX_matrix_inverse %*% XTY_matrix

#MSE:
data_D1=data_D1 %>%
  mutate(yhat2=beta_hat[1,1]+beta_hat[2,1]*X1+beta_hat[3,1]*X2) %>%
  mutate(Ydiff_square2=(yhat2-Pickup.1st.minute)^2)
data_D2=data_D2 %>%
  mutate(yhat2=beta_hat[1,1]+beta_hat[2,1]*X1+beta_hat[3,1]*X2) %>%
  mutate(Ydiff_square2=(yhat2-Pickup.1st.minute)^2)

#Calculated SSE seperately
SSE_D1=sum(data_D1$Ydiff_square2,na.rm = T)
SSE_D2=sum(data_D2$Ydiff_square2,na.rm = T)

#Calculate MSE:
MSE=(SSE_D1+SSE_D2)/(n1+n2-3)

#Variance-covariance matrix:
Varhat_betahat=diag(XTX_matrix_inverse)*c(MSE)
sd_betahat=sqrt(Varhat_betahat)

#t-score:
tscorelist=beta_hat/sd_betahat
plist=2*pt(tscorelist, n1+n2-3, lower.tail = FALSE)


#95% CI
ul=format(beta_hat+tscorelist*sd_betahat,digits=2)
ll=format(beta_hat-tscorelist*sd_betahat,digits=2)


#Output result in a table:

betalist=format(round(beta_hat,4))
sdlist=format(round(sqrt(Varhat_betahat),4))
tscorelist=format(round(tscorelist,4))
pvaluelist=format(round(plist,3))
pvaluelist=str_replace_all(pvaluelist,"0.000","<0.001")

cilist=c(paste0(ul,",",ll))

#federal learning output table
meta_output=cbind(betalist,sdlist,tscorelist,cilist,pvaluelist)

rname=c("Intercept","Total Screen Time","Total Pickups")
cname=c("Coefficient","SD","T-score","95%CI","P-value")
colnames(meta_output)=cname
row.names(meta_output)=rname

kable(meta_output,booktabs = T)


```




# Confirmation analysis: 

## Confirm the analysis:

### Federal learning:

Output from the overall linear regression

```{r, echo=FALSE,error=FALSE,message=FALSE}

data_overall=read.xlsx("data/hotpot_screen_data.xlsx",sheetName ="Overall")

#Transfer the time into minutes:
data_overall=rbind(data_D1,data_D2)

#Regression
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time,data=data_overall)
summary(fit)$coef

```

Output from the federal learning:

```{r, echo=FALSE,error=FALSE,message=FALSE}
kable(fed_output,booktabs = T)
```

The coefficients and SD calculated in the federal learning is the same as the one calculated using overall data. 


### Meta learning:

Results using the overall data:

```{r, echo=FALSE,error=FALSE,message=FALSE}
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Pickups,data=data_overall)
summary(fit)$coef


```

Results using the federal learning method

```{r, echo=FALSE,error=FALSE,message=FALSE}
kable(meta_output,booktabs = T)
```


Separate by individual: stratification


Individual 1

```{r, echo=FALSE,error=FALSE,message=FALSE}
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Pickups,data=data_D1)
summary(fit)$coef
```


Individual 2

```{r, echo=FALSE,error=FALSE,message=FALSE}
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Pickups,data=data_D2)
summary(fit)$coef
```


#Conclusion & Discussion: 






### Sensitivity analysis by individual: Strafitication


#### Federal


Individual 1

```{r, echo=FALSE,error=FALSE,message=FALSE}
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time,data=data_D1)
summary(fit)$coef
```

Individual 2

```{r, echo=FALSE,error=FALSE,message=FALSE}
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time,data=data_D2)
summary(fit)$coef
```



#### Meta

Individual 1

```{r, echo=FALSE,error=FALSE,message=FALSE}
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Pickups,data=data_D1)
summary(fit)$coef
```

Individual 2

```{r, echo=FALSE,error=FALSE,message=FALSE}
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Pickups,data=data_D2)
summary(fit)$coef
```




# Acknowledgement: 

  
# Appendix: 

   