---
title: "Relationship Between Wake-up time and the total screen time in the previous day using Federal and Meta Learning"
author: "Team Hot Pot; Xueting Tao, Isabel Gomez"
date: "2/14/2022"
output:
  rmarkdown::pdf_document:
    fig_caption: yes        
    includes:  
      in_header: my_header.tex
    extra_dependencies: ["float"]
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, error = FALSE, warning = FALSE,fig.pos = "!H", out.extra = "")
library(readxl)
library(lubridate)
library(dplyr)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(GGally)
library(circular)
library(kableExtra)
```


# Abstract: 

## Introduction:

The use of cell-phones and their impact on our daily lives is an ongoing relationship that scientists try to understand. This study focused on the relationship between wake-up time and total screen time in the previous day.

## Method:

The data was collected from two students of Biostatistics 620 class, using the summary report in the cellphone. Since we assume that the individual level data could not be shared, thus federal learning method was applied in the simple linear regression(SLR) and meta learning methods was applied to the multiple linear regression (MLR) adjusted for school days. 

## Results:

We found both insignificant relationship between wake-up time and total screen time in the previous day in both adjusted and unadjusted analysis. The School day is significantly related to earlier wake-up time. Federal learning method yields the same results and SLR using overall data while Meta learning gives slightly different results.

## Conclusion:

We cannot varify the relationship between wake-up time and total screen time in the previous day in this study. Further study might be needed with adjusting more baseline confoundings and with bigger sample size.



# **Introduction:** 

The use of cell-phones and their impact on our daily lives is an ongoing relationship that scientists try to understand. Many studies have shown the impact of phones on various health outcomes such as sleep. A study conducted in 2015, showed that screen time is adversely associated with sleep time [1].  Other studies have shown that cellphone usage is associated with a later wake-up time [2]. Given these findings, we aim to study if a similar pattern arises among the screen time usage in master’s level students at the University of Michigan. The specific data collected includes total screen time in minutes, first pick-up time and the number of pickups in a day. With this specific individual-level data collected, the goal is to better understand phone usage behavior in this group. 

The hypothesis for this study is that screen-time usage is associated with later wake-up times. Here we use the first pick-up time to approximate the wake-up time. In order to test this, we fitted linear regression models using the Federal Learning and the Meta Learning process. In this study we found non-significant relationships between screen time usage and wake-up time. 


# **Data Description:** 



The data was collected between January 3rd, 2022 – February 13, 2022 (20 days) from two students in the Biostatistics 620 class is used in this study. The data was collected both from xuetao’s HUAWEI Mate 30 pro phone and isgomez's iphone. Overall following variables were collected for the study: 

* ID: the umich unique name for the individual, recorded as string type. 
* Date: Recorded everyday, recorded as date type 
* Tot.Soc.Time: Total Social Screen Time for the day, recorded in MM format 
* Pickups: Total numbers of pick-up, recorded as discrete numbers. 
* Pickup.1st: Time at first pick-up, Recorded as time type 


```{r,error = FALSE, warning=FALSE}

#read in screen time data 
screen_data = read_excel(path = "data/hotpot_screen_data.xlsx")

screen_data = screen_data %>% 
  mutate(Pickup.1st = as.POSIXct(paste(as.character(Date),
                                                   unlist(lapply(Pickup.1st,
                                                        function(x){strsplit(as.character(x), split =" ") [[1]] [2]})))))
screen_data_isgomez = screen_data %>% filter(ID == "isgomez")
screen_data_xuetao = screen_data %>% filter(ID == "xuetao")
  summary_data = data.frame(
           ID = rep(c("isgomez","xuetao","hotpot"), times = 3),
           category = c(                                         rep("tot.scr.time", times = 3),
                        rep("tot.soc.time", times = 3), 
                        rep("pickups", times = 3)), 
           # min = c(min(screen_data_isgomez$Pickup.1st),
           #         min(screen_data_xuetao$Pickup.1st),
           #         min(screen_data$Pickup.1st),
            min =  c(min(screen_data_isgomez$Tot.Scr.Time),
                   min(screen_data_xuetao$Tot.Scr.Time),
                   min(screen_data$Tot.Scr.Time),
                   min(screen_data_isgomez$Tot.Soc.Time),
                   min(screen_data_xuetao$Tot.Soc.Time),
                   min(screen_data$Tot.Soc.Time),
                   min(screen_data_isgomez$Pickups),
                   min(screen_data_xuetao$Pickups),
                   min(screen_data$Pickups)), 
           # max = c(max(screen_data_isgomez$Pickup.1st),
           #         max(screen_data_xuetao$Pickup.1st),
           #         max(screen_data$Pickup.1st),
           max =  c(max(screen_data_isgomez$Tot.Scr.Time),
                   max(screen_data_xuetao$Tot.Scr.Time),
                   max(screen_data$Tot.Scr.Time),
                   max(screen_data_isgomez$Tot.Soc.Time),
                   max(screen_data_xuetao$Tot.Soc.Time),
                   max(screen_data$Tot.Soc.Time),
                   max(screen_data_isgomez$Pickups),
                   max(screen_data_xuetao$Pickups),
                   max(screen_data$Pickups)),
           # mean = c(mean(screen_data_isgomez$Pickup.1st),
           #         mean(screen_data_xuetao$Pickup.1st),
           #         mean(screen_data$Pickup.1st),
           mean = c(mean(screen_data_isgomez$Tot.Scr.Time),
                   mean(screen_data_xuetao$Tot.Scr.Time),
                   mean(screen_data$Tot.Scr.Time),
                   mean(screen_data_isgomez$Tot.Soc.Time),
                   mean(screen_data_xuetao$Tot.Soc.Time),
                   mean(screen_data$Tot.Soc.Time),
                   mean(screen_data_isgomez$Pickups),
                   mean(screen_data_xuetao$Pickups),
                   mean(screen_data$Pickups)),
           # median = c(median(screen_data_isgomez$Pickup.1st),
           #         median(screen_data_xuetao$Pickup.1st),
           #         median(screen_data$Pickup.1st),
           median = c(median(screen_data_isgomez$Tot.Scr.Time),
                   median(screen_data_xuetao$Tot.Scr.Time),
                   median(screen_data$Tot.Scr.Time),
                   median(screen_data_isgomez$Tot.Soc.Time),
                   median(screen_data_xuetao$Tot.Soc.Time),
                   median(screen_data$Tot.Soc.Time),
                   median(screen_data_isgomez$Pickups),
                   median(screen_data_xuetao$Pickups),
                   median(screen_data$Pickups)),
           sd = c(sd(screen_data_isgomez$Tot.Scr.Time),
                   sd(screen_data_xuetao$Tot.Scr.Time),
                   sd(screen_data$Tot.Scr.Time),
                   sd(screen_data_isgomez$Tot.Soc.Time),
                   sd(screen_data_xuetao$Tot.Soc.Time),
                   sd(screen_data$Tot.Soc.Time),
                   sd(screen_data_isgomez$Pickups),
                   sd(screen_data_xuetao$Pickups),
                   sd(screen_data$Pickups)))
summary_data2 = summary_data %>% select("ID","min","max","mean","median","sd") %>% mutate(mean = round(mean,0), sd = round(sd,0), median = round(median,0))

```


Table 1 below shows the drastic difference in screen usage and number of pickups between the two participants in this study. As a team, the average amount of total screen time between January 3rd - February 13, 2022 is 421 minutes or approximately 7 hours. The average social screen time is 105 minutes or 1 hour and 45 minutes and the average number of daily pickups was 96.


```{r }

kable(summary_data2, booktabs = TRUE, caption  = "Screen Data Summary Descriptive Statistic per participant") %>% pack_rows(
  index = c("Total Screen Time (in minutes)" = 3, "Total Social Time (in minutes)" = 3, "Number of daily pickups" = 3)) %>%
  kable_styling(font_size = 10, position = "center", full_width = FALSE)
```


Figure 1 displays the pairwise scatter plots of total screen time, social screen time and number of pickups for the group. There is moderately weak significant negative correlation between total screen time and number of pickups (Pearson correlation = -0.292). Social screen time has a weak positive correlation with both total screen time (pearson correlation = 0.035) and number of pickups (pearson correlation = 0.181), both of these are non-significant. 


```{r, fig.height=5, fig.width=7,fig.cap = "Pairwise scatterplot of total screen time, social screen time and total pickup for team hotpot."}
#CORRELATION PLOTS 
ggpairs(screen_data,columns = c("Tot.Scr.Time", "Tot.Soc.Time", "Pickups"),
        columnLabels = c("Total Screen Time", "Social Screen Time", "Total Pickups")) +
  theme_minimal()
```



```{r}
#getting team average screen data info
screen_data$weekday = weekdays(screen_data$Date, abbreviate = T)


# Data Description: 

screen_data = screen_data %>% group_by(Date) %>% mutate(Avg.Total.ST = mean(Tot.Scr.Time),
                                                        Avg.Social.ST = mean(Tot.Soc.Time),
                                                        Avg.Pickups = mean(Pickups))
screen_data = screen_data %>%
  mutate(if_weekend = weekday %in% c("Sun", "Sat")) 

screen_data = screen_data %>%
  group_by(weekday) %>%
  mutate(Avg.Total.ST.wkd = mean(Tot.Scr.Time),
         Avg.Social.ST.wkd = mean(Tot.Soc.Time))

screen_data$weekday  = factor(screen_data$weekday, levels=c("Sun", "Mon", "Tue",
                                        "Wed", "Thu", "Fri", "Sat"))
```

```{r, fig.height=5, fig.width=7, fig.cap = "Time Series Plots (a) - (e) team average total screen time, social screen time, team average total number of pickups, average total screen time by weekday, average social screen time by weekday"}
#total screen time 
total = ggplot(screen_data, aes(x = Date, y = Avg.Total.ST,
                        color = if_weekend)) +
        geom_line(color = "steelblue") + 
        geom_point() +
        labs(x = "", y ="Total Screen Time (min)", caption = "(a) total screen time" ) +
        ylim(15,702) +
        scale_color_manual(labels = c("weekdays", "weekends"), values = 
                            c("black","red")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 60, hjust = 1),
          axis.title.y = element_text(size = 8, hjust = 1),
          plot.caption = element_text(hjust=0.5,vjust = 0.1, size=9),
          legend.title = element_blank())

#social screen time 
social = ggplot(screen_data, aes(x = Date, y = Avg.Social.ST,
                        color = if_weekend)) +
        geom_line(color = "steelblue") + 
        geom_point() +
        labs(x = "", y = "Social Screen Time (min)",caption = "(b) social screen time" ) +
        ylim(15,702) +
        scale_color_manual(labels = c("weekdays", "weekends"), values = 
                            c("black","red")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 60, hjust = 1), 
          axis.title.y = element_text(size= 8, hjust = 1),
          plot.caption = element_text(hjust=0.5,vjust = 0.1, size=9),
          legend.title = element_blank())

#pickups 
pickups = ggplot(screen_data, aes(x = Date, y = Avg.Pickups,
                        color = if_weekend)) +
        geom_line(color = "steelblue") + 
        geom_point() +
        labs(x = "", y = "Total Number of Pickups)", caption = "(c) total pickups") +
        ylim(15,702) +
        scale_color_manual(labels = c("weekdays", "weekends"), values = 
                            c("black","red")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 60, hjust = 1),
          axis.title.y = element_text(size = 7.5),
          plot.caption = element_text(hjust=0.5,vjust = 0.1, size=9),
          legend.title = element_blank())

#weekday total
weekday.total = ggplot(screen_data, aes(x = weekday, y = Avg.Total.ST.wkd)) +
  geom_col() +
  labs(caption = "(d) average total screen time", y = "Average Total Screen Time (min)") +
  theme_minimal() +
  theme(axis.title.y = element_text(size = 8),
         plot.caption = element_text(hjust=0.5,vjust = 0.1, size=9),)

#social total
social.total = ggplot(screen_data, aes(x = weekday, y = Avg.Social.ST.wkd)) +
  geom_col() +
  labs(caption = "(e) average social screen time ", y = "Average Social Screen Time (min)") +
  theme_minimal() +
  theme(axis.title.y = element_text(size = 8), 
        plot.caption = element_text(hjust=0.5,vjust = 0.1, size=9),)
  
grid.arrange(total,social,pickups,weekday.total,social.total, ncol = 2, nrow = 3)
```



```{r}
screen_data = screen_data %>% group_by(Date) %>% mutate(Avg.Pickup.1st = mean(Pickup.1st))
screen_data = screen_data %>% mutate(Pickup.1st.angular = (hour(Avg.Pickup.1st)*60+minute(Avg.Pickup.1st)) / (24*60)*360)

screen_data_isgomez = screen_data_isgomez %>% mutate(Pickup.1st.angular = (hour(Pickup.1st)*60+minute(Pickup.1st)) / (24*60)*360)
screen_data_xuetao = screen_data_xuetao %>% mutate(Pickup.1st.angular = (hour(Pickup.1st)*60+minute(Pickup.1st)) / (24*60)*360)
```

```{r, results = "hide"}
first.pickup.cir.hotpot = circular(screen_data$Pickup.1st.angular, units = "degrees", template = "clock24")

first.pickup.cir.xuetao = circular(screen_data_xuetao$Pickup.1st.angular, units = "degrees", template = "clock24")

first.pickup.cir.isgomez = circular(screen_data_isgomez$Pickup.1st.angular, units = "degrees", template = "clock24")

```


Figure 3 shows the first pick-up time for each member, along with the average of all the participants together. From this figure we can see that the most popular pickup time is around 7:30am. Whereas if we look at the individual pickup time, isgomez has a more variable pickup time with the earliest being at 8:30am and xuetao has a more consolidated pickup time around 7:30am.  

```{r, echo=FALSE,fig.cap="First pick-up time", fig.show="hold", out.width="33%"}
par(mar=c(1,1,1,1))
plot(first.pickup.cir.hotpot, stack=TRUE, bins=24, col = "blue",main="Hotpot")
plot(first.pickup.cir.isgomez, stack=TRUE, bins=24, col = "blue",main="isgomez")
plot(first.pickup.cir.xuetao, stack=TRUE, bins=24, col = "blue",main="xuetao")
```

# Data Preprocessing: 

The data for both individuals was manually combined using an excel spreadsheet. Previous work on
 Data validation was conducted at the individual level, therefore we assume that all the data reported in this spreadsheet is accurate. In order to ensure that all the units are the same, a data transformation was made in the first-pick up time to convert the hours into minutes with midnight being 0 minutes and 11:59pm being 1440 minutes.  An additional variable was made by taking the date and converting it to weekdays (Sunday-Saturday).




# Federated Learning: 


```{r, echo=FALSE,error=FALSE,message=FALSE}

rm(list=ls(all=TRUE))  #same to clear all in stata
cat("\014")

library(xlsx)
library(dplyr)
library(lubridate)
library(stringr)
library(stringi)
library(kableExtra)
#Read in data seperately:
data_D1=read.xlsx("data/hotpot_screen_data.xlsx",sheetName ="isgomez")
data_D2=read.xlsx("data/hotpot_screen_data.xlsx",sheetName ="xuetao")

#Transfer the time into minutes:
data_D1=data_D1 %>%
  mutate(Pickup.1st.minute=(hour(Pickup.1st)*60+minute(Pickup.1st))) %>%
  mutate(pre_Tot.Scr.Time=lag(Tot.Scr.Time),
         pre_Tot.Soc.Time=lag(Tot.Soc.Time),
         X1=pre_Tot.Scr.Time,
         Schoolday=ifelse(Day %in% c("Mo","Tu","We","Th"),1,0),
         X2=Pickups,
         X1Y=X1*Pickup.1st.minute,
         X2Y=X2*Pickup.1st.minute,
         X1square=X1^2,
         X2square=X2^2,
         X1X2=X1*X2,
         pre_pickups=lag(Pickups))
data_D2=data_D2 %>%
  mutate(Pickup.1st.minute=(hour(Pickup.1st)*60+minute(Pickup.1st))) %>%
  mutate(pre_Tot.Scr.Time=lag(Tot.Scr.Time),
         pre_Tot.Soc.Time=lag(Tot.Soc.Time),
         X1=pre_Tot.Scr.Time,
         Schoolday=ifelse(Day %in% c("Mo","Tu","We","Th"),1,0),
         X2=Pickups,
         X1Y=X1*Pickup.1st.minute,
         X2Y=X2*Pickup.1st.minute,
         X1square=X1^2,
         X2square=X2^2,
         X1X2=X1*X2,
         pre_pickups=lag(Pickups))
data_D1=data_D1[complete.cases(data_D1),]
data_D2=data_D2[complete.cases(data_D2),]

```

Let D1 denote the data from team member 1 (Isabel) and D2 denote the data from the team member 2(Xueting). Let Y denote the time of first pick-up the following day and X denote the total screen time for the previous day. Following is the formula we used for the linear regression:

Overall Model:

$Y_i=\beta_0+\beta_1*X_{i}+\epsilon_i$


From the principle of Simple linear regression, we could get following formula for the regression coefficients:

* $\hat{\beta_1}=\frac{SSXY(D1\cup D2)}{SSX(D1 \cup D2)}$ 
* $\hat{\beta_0}=\overline{Y}(D1 \cup D2)-\hat{\beta_1}*\overline{X}(D1 \cup D2)$ 

Overall SSXY and SSX could be obtained by the following way:

* $SSXY(D1 \cup D2)=(n_1+n_2)*\left \{ \overline{XY}(D1 \cup D2)-\overline{X}(D1 \cup D2)*\overline{Y}(D1 \cup D2) \right \}$ 
* $SSX(D1 \cup D2)= (n_1+n_2)*\left \{ \overline{X^2}(D1 \cup D2)-{\overline{X}}^2(D1 \cup D2)\right \}$ 
* $\overline{XY}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{XY}(D1)+\frac{n_2}{n_1+n_2}*\overline{XY}(D2)$ 
* $\overline{X}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{X}(D1)+\frac{n_2}{n_1+n_2}*\overline{X}(D2)$ 
* $\overline{Y}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{Y}(D1)+\frac{n_2}{n_1+n_2}*\overline{Y}(D2)$ 
* $\overline{X^2}(D1 \cup D2)=\frac{n_1}{n_1+n_2}*\overline{X^2}(D1)+\frac{n_2}{n_1+n_2}*\overline{X^2}(D2)$ 

Also, we learned that the Standard Diviation for $\beta_1$ is defined as the following:

* $SD(\hat{\beta_1})=\sqrt{\hat{Var(\hat{\beta_1})}}=\sqrt{\frac{MSE(D1 \cup D2)}{SSX(D1 \cup D2)}}$ 
* $SD(\hat{\beta_0})=\sqrt{\hat{Var(\hat{\beta_0})}}=\sqrt{MSE*(\frac{1}{n}+\frac{\overline{X}^2(D1 \cup D2)}{SSX(D1 \cup D2)}})$ 

$MSE(D1 \cup D2)$ could be obtained by the following formula: 

* $MSE(D1 \cup D2)=\frac{SSE(D1)+SSE(D2)}{n_1+n_2-2}$ 
* $SSE=\sum_{i=1}^{n}(Y_i-\hat{Y_i})^2$ 

To test Whether the slope ($\beta_1$) is significant from 0, we use the following t-test:

* $\frac{\hat{\beta_1}-\beta_1}{\sqrt{\frac{MSE(D1 \cup D2)}{SSX(D1 \cup D2)}}}\sim t_{n_1+n_2-2}$ 

where $\beta_1=0$


Following Table 2 is the result utiliziing the method above:

```{r, echo=FALSE,error=FALSE,message=FALSE}


n1=nrow(data_D1)
n2=nrow(data_D2)
#Indivdual mean
XY_D1_bar=mean(data_D1$X1Y,na.rm = T)
XY_D2_bar=mean(data_D2$X1Y,na.rm = T)
X_D1_bar=mean(data_D1$pre_Tot.Scr.Time,na.rm = T)
X_D2_bar=mean(data_D2$pre_Tot.Scr.Time,na.rm = T)
Y_D1_bar=mean(data_D1$Pickup.1st.minute,na.rm = T)
Y_D2_bar=mean(data_D2$Pickup.1st.minute,na.rm = T)
Xsquare_D1_bar=mean(data_D1$X1square,na.rm = T)
Xsquare_D2_bar=mean(data_D2$X1square,na.rm = T)
#Overall mean:
XY_D1D2_bar=n1/(n1+n2)*XY_D1_bar+n2/(n1+n2)*XY_D2_bar
Y_D1D2_bar=n1/(n1+n2)*Y_D1_bar+n2/(n1+n2)*Y_D2_bar
X_D1D2_bar=n1/(n1+n2)*X_D1_bar+n2/(n1+n2)*X_D2_bar
Xsquare_D1D2_bar=n1/(n1+n2)*Xsquare_D1_bar+n2/(n1+n2)*Xsquare_D2_bar
#SSX and SSXY:
SSXY_D1D2=(n1+n2)*(XY_D1D2_bar-X_D1D2_bar*Y_D1D2_bar)
SSX_D1D2=(n1+n2)*(Xsquare_D1D2_bar-(X_D1D2_bar)^2)
beta1_hat=SSXY_D1D2/SSX_D1D2
beta0_hat=Y_D1D2_bar-beta1_hat*X_D1D2_bar
#Pass the estimates back to the individual dataset to get the SSE:
data_D1=data_D1 %>%
  mutate(Yhat=beta0_hat+beta1_hat*pre_Tot.Scr.Time) %>%
  mutate(Ydiff_square=(Yhat-Pickup.1st.minute)^2)
data_D2=data_D2 %>%
  mutate(Yhat=beta0_hat+beta1_hat*pre_Tot.Scr.Time) %>%
  mutate(Ydiff_square=(Yhat-Pickup.1st.minute)^2)

#Calculated SSE seperately
SSE_D1=sum(data_D1$Ydiff_square,na.rm = T)
SSE_D2=sum(data_D2$Ydiff_square,na.rm = T)

#Calculate MSE:
MSE=(SSE_D1+SSE_D2)/(n1+n2-2)

#Calculate SE(beta1_hat):
SD_beta1_hat=sqrt(MSE/SSX_D1D2)
SD_beta0_hat=sqrt(MSE*(1/(n1+n2)+(X_D1D2_bar)^2/SSX_D1D2))

#T score and p value
beta1_tscore=beta1_hat/SD_beta1_hat
beta1_p=2*(1-pt(q=abs(beta1_tscore),df=n1+n2-2))


beta0_tscore=beta0_hat/SD_beta0_hat
beta0_p=2*(1-pt(q=abs(beta0_tscore),df=n1+n2-2))

#95% CI
# beta1_ul=format(beta1_hat+beta1_tscore*SD_beta1_hat,digits=2)
# beta1_ll=format(beta1_hat-beta1_tscore*SD_beta1_hat,digits=2)
# 
# beta0_ul=format(beta1_hat+beta0_tscore*SD_beta0_hat,digits=2)
# beta0_ll=format(beta1_hat-beta0_tscore*SD_beta0_hat,digits=2)

#Output result in a table:
betalist=format(round(c(beta0_hat,beta1_hat),4))
sdlist=format(round(c(SD_beta0_hat,SD_beta1_hat),4))
tscorelist=format(round(c(beta0_tscore,beta1_tscore),4))
pvaluelist=format(round(c(beta0_p,beta1_p),3))

pvaluelist=str_replace_all(pvaluelist,"0.000","<0.001")

# cilist=c(paste0(beta0_ll,",",beta0_ul),paste0(beta1_ll,",",beta1_ul))

#federal learning output table
fed_output=cbind(betalist,sdlist,tscorelist,pvaluelist)

rname=c("Intercept","Total Screen Time")
cname=c("Coefficient","SD","T-score","P-value")
colnames(fed_output)=cname
row.names(fed_output)=rname

kable(fed_output,booktabs = T,caption = "Federal learning result")

```

From the result above, we found that the estimated $\hat{\beta_1}$ is `r beta1_hat`, with SD=`r SD_beta1_hat`. The calculated P value is `r beta1_p` which is more than 0.05, which is non-significant. 
This results shows that there might be positive relationship between the first pick-up and the total screen time in the previous day but the relationship is not significant.

# Meta Learning: 


Overall Model:

$Y_i=\beta_0+\beta_1*X_{i1}+\beta_2*X_{i2+}\epsilon_i$

where :

* $Y_i$ refers to First Pickup time. 
* $X_{i1}$ refers to Total Screen time in the previous day 
* $X_{i2}$ refers to School day(Which Monday to Thursday as school day and Friday to Sunday as non-school day)

First we calculate the 2 individual $\hat{\beta}$ and $\hat{Var\hat{(\beta)}}$ to get the $\hat{\beta^{(1)}}$,  $\hat{\beta^{(2)}}$ and $\hat{Var\hat{(\beta^{(1)})}}$, $\hat{Var\hat{(\beta^{(2)})}}$. 

To get the best unbiased estimator, we need to minimum variance as the following:

$minVar[c_1\hat{\theta}_1+c_2\hat{\theta}_2]$ and set $c_1+c_2=1$. As a result, we could calculate the estimate and variance as the following:

Then the $\hat{\beta}^{meta}$ could be calculated using the following formula:

$\hat{\beta}^{meta}=\frac{\hat{\beta^{(1)}}/\hat{Var\hat{(\beta^{(1)})}}+\hat{\beta^{(2)}}/\hat{Var\hat{(\beta^{(2)})}}}{1/\hat{Var\hat{(\beta^{(1)})}}+1/\hat{Var\hat{(\beta^{(2)})}}}$



$\hat{Var\hat{(\beta^{meta})}}=\frac{1}{1/\hat{Var\hat{(\beta^{(1)})}}+1/\hat{Var\hat{(\beta^{(2)})}}}$

Below Table 4 is the meta learning result.

```{r}
#Calculating individual beta:
fit1=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Schoolday,data=data_D1)
fit2=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Schoolday,data=data_D2)

beta0_hat1=summary(fit1)$coef[1,1]
beta0_hat2=summary(fit2)$coef[1,1]

beta1_hat1=summary(fit1)$coef[2,1]
beta1_hat2=summary(fit2)$coef[2,1]

beta2_hat1=summary(fit1)$coef[3,1]
beta2_hat2=summary(fit2)$coef[3,1]

var_beta0hat1=(summary(fit1)$coef[1,2])^2
var_beta0hat2=(summary(fit2)$coef[1,2])^2

var_beta1hat1=(summary(fit1)$coef[2,2])^2
var_beta1hat2=(summary(fit2)$coef[2,2])^2

var_beta2hat1=(summary(fit1)$coef[3,2])^2
var_beta2hat2=(summary(fit2)$coef[3,2])^2

beta0_hat=(beta0_hat1/var_beta0hat1+beta0_hat2/var_beta0hat2)/(1/var_beta0hat1+1/var_beta0hat2)
beta1_hat=(beta1_hat1/var_beta1hat1+beta1_hat2/var_beta1hat2)/(1/var_beta1hat1+1/var_beta1hat2)
beta2_hat=(beta2_hat1/var_beta2hat1+beta2_hat2/var_beta2hat2)/(1/var_beta2hat1+1/var_beta2hat2)

var_beta0hat=1/(1/var_beta0hat1+1/var_beta0hat2)
var_beta1hat=1/(1/var_beta1hat1+1/var_beta1hat2)
var_beta2hat=1/(1/var_beta2hat1+1/var_beta2hat2)

SD_beta0_hat=sqrt(var_beta0hat)
SD_beta1_hat=sqrt(var_beta1hat)
SD_beta2_hat=sqrt(var_beta2hat)

#T test:

beta0_tscore=beta0_hat/SD_beta0_hat
beta0_p=2*(1-pt(q=abs(beta0_tscore),df=n1+n2-2))

beta1_tscore=beta1_hat/SD_beta1_hat
beta1_p=2*(1-pt(q=abs(beta1_tscore),df=n1+n2-2))

beta2_tscore=beta2_hat/SD_beta2_hat
beta2_p=2*(1-pt(q=abs(beta2_tscore),df=n1+n2-2))

# #95% CI
# beta1_ul=format(beta1_hat+beta1_tscore*SD_beta1_hat,digits=2)
# beta1_ll=format(beta1_hat-beta1_tscore*SD_beta1_hat,digits=2)
# 
# beta2_ul=format(beta1_hat+beta2_tscore*SD_beta2_hat,digits=2)
# beta2_ll=format(beta1_hat-beta2_tscore*SD_beta2_hat,digits=2)

#Output result in a table:
betalist=format(round(c(beta0_hat,beta1_hat,beta2_hat),4))
sdlist=format(round(c(SD_beta0_hat,SD_beta1_hat,SD_beta2_hat),4))
tscorelist=format(round(c(beta0_tscore,beta1_tscore,beta2_tscore),4))
pvaluelist=format(round(c(beta0_p,beta1_p,beta2_p),3))

pvaluelist=str_replace_all(pvaluelist,"0.000","<0.001")

#cilist=c(paste0(beta1_ll,",",beta1_ul),paste0(beta2_ll,",",beta2_ul))

#federal learning output table
meta_output=cbind(betalist,sdlist,tscorelist,pvaluelist)

rname=c("Intercept","Total Screen Time","School Day")
cname=c("Coefficient","SD","T-score","P-value")
colnames(meta_output)=cname
row.names(meta_output)=rname

kable(meta_output,booktabs = T,caption = "Meta learning result")

# 
# data_overall=rbind(data_D1,data_D2)
# fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Schoolday,data=data_overall)
# summary(fit)
# 
# beta1_hat1
# beta1_hat2
# beta1_hat
# 
# beta2_hat1
# beta2_hat2
# beta2_hat
# 
# summary(fit1)
# summary(fit2)

```



# Confirmation analysis: 

## Confirm the analysis:

### Federal learning:



```{r, echo=FALSE,error=FALSE,message=FALSE}


#Transfer the time into minutes:
data_overall=rbind(data_D1,data_D2)

#Regression
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time,data=data_overall)
tbl=round(summary(fit)$coef,4)
tbl[,4]=ifelse(tbl[,4]==0,"<0.001",tbl[,4])
tbl=rbind(c(NA,NA,NA,NA),tbl,c(NA,NA,NA,NA))


#Federal learning
tbl=rbind(tbl,fed_output)
tbl=cbind(c(NA,"Intercept","Total Screen time",NA,"Intercept","Total Screen time"),tbl)
row.names(tbl)=c("Regression",NA,NA,"Federal learning",NA,NA)
options(knitr.kable.NA = '')
kable(tbl,booktabs=T,caption = "Validate of Federal learning")

```


The coefficients and SD calculated in the federal learning is the same as the one calculated using overall data. 


### Meta learning:

Results using the overall data:

```{r, echo=FALSE,error=FALSE,message=FALSE}
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Schoolday,data=data_overall)

tbl=round(summary(fit)$coef,4)
tbl[,4]=ifelse(tbl[,4]==0,"<0.001",tbl[,4])
tbl=rbind(c(NA,NA,NA,NA),tbl,c(NA,NA,NA,NA))


#Federal learning
tbl=rbind(tbl,meta_output)
tbl=cbind(c(NA,"Intercept","Total Screen time","School Day",NA,"Intercept","Total Screen time","School day"),tbl)
row.names(tbl)=c("Regression",NA,NA,NA,"Federal learning",NA,NA,NA)
options(knitr.kable.NA = '')
kable(tbl,booktabs=T,caption = "Validate of Meta learning")


```

As a result, the federal learning estimate and variance is the same as the one we calculated using the overall data while the meta learning result is a little bit different from the one we calculated using the overall result.


# Conclusion & Discussion: 

To conclude, this study shows that there is a non-significant relationship between wake-up time and total screen time both in crude analysis and after adjusting for the School days. However, the School day has a significantly associated with earlier wake-up time, which might result from the need of early class. 

This might be happening because the two individuals in the team have very different patterns of screen usage. As shown in figure3, xuetao has a more constrained wake-up time and isgomez has a more spread wake-up time. This might happen because the two individuals have different schedules for class. Thus, we further do a separated linear regression for both individuals. 

As shown in the Appendix 1, For isgomez, in both crude and adjusted analysis, the significant level raised a little bit for total screen time  but still not significant. The school day turns to be non-significant in the adjusted analysis. For xuetao, the significant level of total screen time decrease a little bit in the unadjusted analysis and raised a little bit in the adjusted analysis. The significant level for school day raised a little bit in the adjusted analysis. This indicates that the two individual indeed have different habit of screen usage and the combined result might be unreliable because of the difference between two individuals.

Also, the non-significant relationship might because of small sample size of the study. Since each of us only have 30 observations which leads to higher variance, thus more uncertainty. Moreover, there might be other baseline covraites like class hours, and demographic variables that influence the study. Furthermore, since we are using the first pick-up time to approximate the wake-up time, this approximation could also be biased some time. Further study might be needed to adjusted for more covariates , increase the sample size and have a better approximation of wake-up time.

### What was your experience of data analysis, especially in the aspect of team collaboration? 

From this data analysis experience, we noticed the importance of alignment of data collecting. For example, although we have the same data frozen time, we didn’t actually have the same data enrollment date. This results in different lines of data for the two individuals. As a result, we decided to keep the same date that we both have data in order to make both of our data have similar weight. In the future study, it is not only important to control the study end time but also to control study enrollment time.

Also, from this analysis, we decided to separate the analysis into data description and federal/meta learning. Both of us contribute to our strength and after communicate after we finished our parts, we both learned a lot from each other.

### Summarize your main contributions and findings in this project. 

Xueting worked on the Federal Learning and Meta Analysis,and edited the write-up report. Isabel worked on the data description, writing and editing the report. Both teammates contribute to the written-up of the team report. This study highlighted the difference in cell-phone usage among individuals, even when they have the same occupation (student). 

# Acknowledgement: 

We would like to express my special thanks to my teacher(Peter Song) as well as GSI(Yuan Zhong) who have been giving us quick and helpful response. Also, we would like to thank my kindly classmates, Wenchu Pan, Xin Luo and Yuntian Wu for their help in understaning of Meta Learning.
  
# Appendix: 

```{r, echo=FALSE,error=FALSE,message=FALSE}
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time,data=data_D1)
unadjust_coef_isgomez=round(fit$coefficients[2],3)
unadjust_p_isgomez=round(summary(fit)$coef[2,4],3)
unadjust_isgomez=c(unadjust_coef_isgomez,unadjust_p_isgomez)

fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Schoolday,data=data_D1)
adjust_coef_isgomez=round(fit$coef[-1],3)
adjust_p_isgomez=round(summary(fit)$coef[,4][-1],3)
adjust_isgomez=cbind(adjust_coef_isgomez,adjust_p_isgomez)

tbl=c(NA,NA)
tbl=rbind(c(NA,NA),adjust_isgomez,c(NA,NA),unadjust_isgomez)
colnames(tbl)=c("Coef","p-value")
tbl=cbind(c(NA,"Total Screen time(in previous day)","School day",NA,"Total Screen time"),tbl)
row.names(tbl)=c("Ajusted",NA,NA,"Unadjusted",NA)
options(knitr.kable.NA = '')
kable(tbl,booktabs=T,caption="Appendix 1a: Stratified analysis for isgomez")
```


```{r, echo=FALSE,error=FALSE,message=FALSE}
fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time,data=data_D2)
unadjust_coef_isgomez=round(fit$coefficients[2],3)
unadjust_p_isgomez=round(summary(fit)$coef[2,4],3)
unadjust_isgomez=c(unadjust_coef_isgomez,unadjust_p_isgomez)

fit=lm(Pickup.1st.minute~pre_Tot.Scr.Time+Schoolday,data=data_D2)
adjust_coef_isgomez=round(fit$coef[-1],3)
adjust_p_isgomez=round(summary(fit)$coef[,4][-1],3)
adjust_isgomez=cbind(adjust_coef_isgomez,adjust_p_isgomez)

tbl=c(NA,NA)
tbl=rbind(c(NA,NA),adjust_isgomez,c(NA,NA),unadjust_isgomez)
colnames(tbl)=c("Coef","p-value")
tbl=cbind(c(NA,"Total Screen time(in previous day)","School day",NA,"Total Screen time"),tbl)
row.names(tbl)=c("Ajusted",NA,NA,"Unadjusted",NA)
options(knitr.kable.NA = '')
kable(tbl,booktabs=T,caption="Appendix 1b: Stratified analysis for xuetao")
```

# Reference:
  
  + [1]. Hale, L., & Guan, S. (2015). Screen time and sleep among school-aged children and adolescents: a systematic literature review. Sleep medicine reviews, 21, 50–58. https://doi.org/10.1016/j.smrv.2014.07.007 
  + [2]. Hiltunen P, Leppänen MH, Ray C, Määttä S, Vepsäläinen H, Koivusilta L, Sajaniemi N, Erkkola M, Roos E. Relationship between screen time and sleep among Finnish preschool  
   